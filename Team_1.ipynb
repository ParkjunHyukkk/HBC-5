{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team-1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LI8Za96CkXHp"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI8Za96CkXHp"
      },
      "source": [
        "\n",
        "\n",
        "#python 버전을 맞추기 위한 코드\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaD3LN_2jd3_"
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAec566ylAjn"
      },
      "source": [
        "import tensorflow as tf \n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR4geAF4mAV9"
      },
      "source": [
        "pip uninstall keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHM14dZ9mExc"
      },
      "source": [
        "pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maYo0VMzpCL-"
      },
      "source": [
        "!pip uninstall numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBlsR7sTpJOc"
      },
      "source": [
        "!pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXxKDTKnJyj0"
      },
      "source": [
        "#코드 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t154ETxfzTq"
      },
      "source": [
        "\"\"\"\n",
        "from PIL import Image,ImageFilter,ImageEnhance\n",
        "import os, glob, numpy as np\n",
        "import cv2 as cv\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "caltech_dir = \"/content/drive/My Drive/trainig\" #트레이닝 데이터 경로\n",
        "categories = [\"0\", \"1\", \"2\", \"3\",\"4\"] #라벨 이름\n",
        "nb_classes = len(categories) \n",
        "\n",
        "#이미지 resize 크기 설정\n",
        "image_w = 64 \n",
        "image_h = 64\n",
        "\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "\n",
        "for idx, cat in enumerate(categories):\n",
        "    \n",
        "    #one-hot 돌리기.\n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "\n",
        "    image_dir = caltech_dir + \"/\" + cat\n",
        "    files = glob.glob(image_dir+\"/*.*\")\n",
        "    print(cat, \" 파일 길이 : \", len(files))\n",
        "    \n",
        "\n",
        "    gaussianBlur = ImageFilter.GaussianBlur(5)#가우시안 필터\n",
        "    contour = ImageFilter.CONTOUR()#윤곽선 적용\n",
        "    enhance = ImageFilter.EDGE_ENHANCE()#엣지\n",
        "    mean = ImageFilter.MedianFilter()\n",
        "    max = ImageFilter.MaxFilter()\n",
        "    min = ImageFilter.MinFilter()\n",
        "    for i, f in enumerate(files):\n",
        "        \n",
        "        img = Image.open(f)#이미지 불러오기\n",
        "        img = img.convert(\"LA\")#2채널 회색조로 변형\n",
        "\n",
        "        img = img.resize((image_w, image_h))#이미지 resize\n",
        "        #img = img.filter(gaussianBlur)#가우시안필터적용\n",
        "        #img = img.filter(contour)\n",
        "        img = img.filter(enhance)\n",
        "        img = img.filter(max)\n",
        "        #img = img.filter(mean)\n",
        "\n",
        "\n",
        "        data = np.asarray(img)#img를 np형태로 저장\n",
        "\n",
        "        X.append(data)#appned로 데이터 이어 붙이기\n",
        "        y.append(label)#라벨 이어붙이기\n",
        "\n",
        "        if i % 700 == 0:\n",
        "            print(cat, \" : \", f)\n",
        "      \n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "img.show()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "np.save(\"/content/drive/My Drive/numpy_data/multi_image_data.npy\", xy)\n",
        "\n",
        "print(\"이미지 총 갯수 : \", len(y))\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-_jO9wOhJIK"
      },
      "source": [
        "\"\"\"\n",
        "import os, glob, numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend.tensorflow_backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config)\n",
        "\n",
        "X_train, X_test, y_train, y_test = np.load('/content/drive/My Drive/numpy_data/multi_image_data.npy')\n",
        "print(X_train.shape)\n",
        "print(X_train.shape[0])\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cUBNL0SpYbc"
      },
      "source": [
        "\"\"\"\n",
        "categories = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
        "nb_classes = len(categories)\n",
        "\n",
        "#일반화\n",
        "X_train = X_train.astype(float) / 255\n",
        "X_test = X_test.astype(float) / 255\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O38at2uFppvk"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "with K.tf_ops.device('/device:GPU:0'):#gpu 사용\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu')) #2d convolution 적용 activition은 relu 사용\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu')) #2d convolution 적용 activition은 relu 사용\n",
        "    model.add(MaxPooling2D(pool_size=(2,2))) #max pooling 필터 영역별 최고값 조절\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu')) \n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(nb_classes, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model_dir = './model'\n",
        "    \n",
        "    if not os.path.exists(model_dir):\n",
        "        os.mkdir(model_dir)\n",
        "    \n",
        "    model_path = model_dir + '/multi_img_classification.model'\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
        "    \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6JdNw3nrU5d"
      },
      "source": [
        "#history = model.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGWp9Blk54LM"
      },
      "source": [
        "#print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RakWlGhsBoE"
      },
      "source": [
        "\"\"\"\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAYGKupGh7OO",
        "outputId": "08cb8079-6866-4bfb-88ae-3649e7cdc4db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL8Y2p5PsfIs",
        "outputId": "8bc6b209-2175-4983-ae4b-9009e9004163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from PIL import Image,ImageFilter,ImageEnhance\n",
        "import os, glob, numpy as np\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "categories = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
        "nb_classes = len(categories)\n",
        "\n",
        "\n",
        "enhance = ImageFilter.EDGE_ENHANCE()#엣지\n",
        "max = ImageFilter.MaxFilter()\n",
        "\n",
        "#gaussianBlur = ImageFilter.GaussianBlur(5)\n",
        "X = []\n",
        "y = []\n",
        "filenames = []\n",
        "\n",
        "\n",
        "for building_index in categories:\n",
        "  idx = int(building_index)\n",
        "  print(\"Reading building: \", idx)\n",
        "\n",
        "  caltech_dir = \"/content/drive/My Drive/SW-WEEK/HBC-5-2020/FinalTestDataset\" + '/' + building_index\n",
        "  print(caltech_dir)\n",
        "\n",
        "  #files = glob.glob(caltech_dir+\"/*/*.*\")\n",
        "  files = glob.glob(caltech_dir+\"/*.*\")\n",
        "\n",
        "  for i, f in enumerate(files):\n",
        "      img = Image.open(f)\n",
        "      img = img.convert(\"LA\")   \n",
        "      img = img.filter(enhance)\n",
        "      img = img.filter(max)\n",
        "      img = img.resize((image_w, image_h))\n",
        "      data = np.asarray(img)\n",
        "      filenames.append(f)\n",
        "      X.append(data)\n",
        "\n",
        "      #one-hot 돌리기.\n",
        "      label = [0 for i in range(nb_classes)]\n",
        "      label[idx] = 1\n",
        "      y.append(label)#라벨 이어붙이기\n",
        "\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(np.array(X), np.array(y))\n",
        "# X_train2, X_test2, y_train2, y_test2 = train_test_split(np.array(X), np.array(y))\n",
        "# xy = (X_train, X_test, y_train, y_test)\n",
        "# np.save(\"/content/drive/My Drive/numpy_data/multi_image_data.npy\", xy)\n",
        "# 불러오고\n",
        "# 일반화\n",
        "X_train1 = np.array(X_train1).astype(float) / 255\n",
        "X_test1 = np.array(X_test1).astype(float) / 255\n",
        "#X_train2 = np.array(X_train2).astype(float) / 255\n",
        "#X_test2 = np.array(X_test2).astype(float) / 255\n",
        "\n",
        "print('done')  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading building:  0\n",
            "/content/drive/My Drive/SW-WEEK/HBC-5-2020/FinalTestDataset/0\n",
            "Reading building:  1\n",
            "/content/drive/My Drive/SW-WEEK/HBC-5-2020/FinalTestDataset/1\n",
            "Reading building:  2\n",
            "/content/drive/My Drive/SW-WEEK/HBC-5-2020/FinalTestDataset/2\n",
            "Reading building:  3\n",
            "/content/drive/My Drive/SW-WEEK/HBC-5-2020/FinalTestDataset/3\n",
            "Reading building:  4\n",
            "/content/drive/My Drive/SW-WEEK/HBC-5-2020/FinalTestDataset/4\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvW_wnfufK9J",
        "outputId": "99a6792b-8d5f-45df-b33c-780bcb6994b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = load_model('/content/drive/My Drive/SW-WEEK/HBC-5-2020/Team-1-Model/multi_img_classification.model')\n",
        "\n",
        "# 우리가 가진 데이터 \n",
        "#X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y)\n",
        "\n",
        "loss1, acc1 = model.evaluate(X_train1, y_train1)\n",
        "loss2, acc2 = model.evaluate(X_test1, y_test1)\n",
        "\n",
        "size1 = len(X_train1)\n",
        "size2 = len(X_test1)\n",
        "size_sum = size1 + size2\n",
        "final_accuracy = (acc1 * size1 / size_sum) + (acc2 * size2 / size_sum)\n",
        "\n",
        "print('Final accuracy : ', (acc1 + acc2) / 2.0 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 3s 56ms/step - loss: 7.0180 - accuracy: 0.3547\n",
            "20/20 [==============================] - 1s 52ms/step - loss: 6.6255 - accuracy: 0.3696\n",
            "Final accuracy :  0.36213333904743195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkLsowNGT_KZ",
        "outputId": "105bdd0d-5c48-4c5a-fc52-371d47ccb568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(acc1, acc2)\n",
        "\n",
        "size1 = len(X_train1)\n",
        "print(size1)\n",
        "\n",
        "size2 = len(X_test1)\n",
        "print(size2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.35466668009757996 0.36959999799728394\n",
            "1875\n",
            "625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}